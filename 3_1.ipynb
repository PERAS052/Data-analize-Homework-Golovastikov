{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# =============================================================================\n",
        "# Семинар 3. ИДС / NLP\n",
        "# Частотный анализ повести Пушкина «Метель»\n",
        "# Облака слов, POS-фильтрация, синтаксические зависимости\n",
        "# ============================================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# ─── 1. Импорты и настройки ──────────────────────────────────────────────────\n",
        "\n",
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-v0_8-pastel')\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "%pip install pymorphy3 -q\n",
        "import pymorphy3\n",
        "\n",
        "%pip install spacy ru_core_news_sm -q\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "print(\"Все необходимые библиотеки загружены\\n\")\n",
        "\n",
        "# ─── 2. Чтение и начальная очистка текста ────────────────────────────────────\n",
        "\n",
        "with open('pushkin-metel.txt', 'r', encoding='utf-8') as fh:\n",
        "    original_text = fh.read()\n",
        "\n",
        "print(f\"Длина исходного текста: {len(original_text):,} символов\")\n",
        "print(\"Первые 220 символов:\\n\", original_text[:220], \"...\\n\")\n",
        "\n",
        "# Приведение к нижнему регистру + удаление пунктуации и цифр\n",
        "clean_text = original_text.lower()\n",
        "clean_text = re.sub(r'[^\\w\\sа-яё]', '', clean_text)          # всё кроме букв и пробелов\n",
        "clean_text = re.sub(r'\\s+', ' ', clean_text).strip()\n",
        "\n",
        "print(\"Длина после базовой очистки:\", len(clean_text))\n",
        "print(\"Пример:\", clean_text[:180], \"...\\n\")\n",
        "\n",
        "# ─── 3. Токенизация и частотный словарь (до стоп-слов) ───────────────────────\n",
        "\n",
        "tokens_raw = word_tokenize(clean_text, language='russian')\n",
        "print(f\"Всего токенов: {len(tokens_raw):,}\")\n",
        "\n",
        "freq_raw = FreqDist(tokens_raw)\n",
        "\n",
        "print(\"\\nТоп-15 слов до удаления стоп-слов:\")\n",
        "for word, cnt in freq_raw.most_common(15):\n",
        "    print(f\"{word:>10}  {cnt:>6}\")\n",
        "\n",
        "plt.figure(figsize=(11, 5))\n",
        "freq_raw.plot(30, title=\"Топ-30 слов (включая служебные)\", cumulative=False)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# ─── 4. Фильтрация стоп-слов ─────────────────────────────────────────────────\n",
        "\n",
        "ru_stops = set(stopwords.words('russian'))\n",
        "ru_stops.update(['это', 'было', 'стал', 'быть', 'который', 'тот', 'сам', 'всё', 'сказал'])\n",
        "\n",
        "tokens_filtered = [t for t in tokens_raw if t not in ru_stops and len(t) > 2]\n",
        "\n",
        "print(f\"Токенов после фильтрации: {len(tokens_filtered):,}\")\n",
        "\n",
        "freq_filtered = FreqDist(tokens_filtered)\n",
        "\n",
        "print(\"\\nТоп-12 значимых слов:\")\n",
        "for w, c in freq_filtered.most_common(12):\n",
        "    print(f\"{w:>12} : {c:>5}\")\n",
        "\n",
        "plt.figure(figsize=(10, 4.5))\n",
        "freq_filtered.plot(25, title=\"Топ-25 после удаления стоп-слов\")\n",
        "plt.show()\n",
        "\n",
        "# ─── 5. Общее облако слов ────────────────────────────────────────────────────\n",
        "\n",
        "text_for_cloud = ' '.join(tokens_filtered)\n",
        "\n",
        "cloud_all = WordCloud(\n",
        "    width=1000, height=600,\n",
        "    background_color='linen',\n",
        "    colormap='Dark2',\n",
        "    max_words=200,\n",
        "    min_font_size=10, max_font_size=180\n",
        ").generate(text_for_cloud)\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.imshow(cloud_all, interpolation='bicubic')\n",
        "plt.axis('off')\n",
        "plt.title(\"Облако слов — «Метель» Пушкина (без стоп-слов)\")\n",
        "plt.show()\n",
        "\n",
        "# ─── 6. POS-анализ и облака по частям речи (pymorphy3) ──────────────────────\n",
        "\n",
        "morph = pymorphy3.MorphAnalyzer()\n",
        "\n",
        "nouns, verbs, adjs = [], [], []\n",
        "\n",
        "for token in tokens_filtered:\n",
        "    p = morph.parse(token)[0]\n",
        "    pos = p.tag.POS\n",
        "    \n",
        "    if pos == 'NOUN':\n",
        "        nouns.append(p.normal_form)\n",
        "    elif pos in ('VERB', 'INFN'):\n",
        "        verbs.append(p.normal_form)\n",
        "    elif pos in ('ADJF', 'ADJS'):\n",
        "        adjs.append(p.normal_form)\n",
        "\n",
        "print(f\"Существительных: {len(nouns):,}\")\n",
        "print(f\"Глаголов/инфинитивов: {len(verbs):,}\")\n",
        "print(f\"Прилагательных: {len(adjs):,}\\n\")\n",
        "\n",
        "noun_counter = Counter(nouns)\n",
        "verb_counter = Counter(verbs)\n",
        "adj_counter  = Counter(adjs)\n",
        "\n",
        "# Топ по каждой категории\n",
        "print(\"Топ-7 существительных:\", noun_counter.most_common(7))\n",
        "print(\"Топ-7 глаголов     :\", verb_counter.most_common(7))\n",
        "print(\"Топ-7 прилагательных:\", adj_counter.most_common(7))\n",
        "\n",
        "# Облака слов по частям речи\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "cloud_n = WordCloud(background_color='azure', colormap='Blues', width=600, height=400).generate_from_frequencies(noun_counter)\n",
        "axes[0].imshow(cloud_n, interpolation='bilinear')\n",
        "axes[0].set_title('Существительные')\n",
        "axes[0].axis('off')\n",
        "\n",
        "cloud_v = WordCloud(background_color='oldlace', colormap='OrRd', width=600, height=400).generate_from_frequencies(verb_counter)\n",
        "axes[1].imshow(cloud_v, interpolation='bilinear')\n",
        "axes[1].set_title('Глаголы')\n",
        "axes[1].axis('off')\n",
        "\n",
        "cloud_a = WordCloud(background_color='honeydew', colormap='Greens', width=600, height=400).generate_from_frequencies(adj_counter)\n",
        "axes[2].imshow(cloud_a, interpolation='bilinear')\n",
        "axes[2].set_title('Прилагательные')\n",
        "axes[2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ─── 7. Синтаксические зависимости (spacy) ──────────────────────────────────\n",
        "\n",
        "nlp = spacy.load(\"ru_core_news_sm\")\n",
        "\n",
        "# Берём первые 6 предложений из оригинального текста\n",
        "doc_full = nlp(original_text)\n",
        "first_sents = list(doc_full.sents)[:6]\n",
        "\n",
        "print(\"Синтаксические зависимости — первые 6 предложений\\n\")\n",
        "\n",
        "for i, sentence in enumerate(first_sents, 1):\n",
        "    print(f\"Предложение {i}:\\n{sentence.text.strip()}\\n\")\n",
        "    displacy.render(sentence, style=\"dep\", jupyter=True,\n",
        "                    options={'distance': 105, 'compact': True, 'bg': '#118ab2', 'color': '#ffffff'})\n",
        "    print(\"─\" * 90 + \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
