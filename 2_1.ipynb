{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pEohOMqNxu0W"
      },
      "outputs": [],
      "source": [
        "#код генерирующий стихи Пушкин\n",
        "import re\n",
        "import json\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Длина текста после очистки: 659,217 символов\n",
            "Начало текста: Жил-был поп, Толоконный лоб. Пошел поп по базару Посмотреть кой-какого товару. Навстречу ему Балда. Идет, сам не зная куда. «Что, батька, так рано поднялся? Чего ты взыскался?» Поп ...\n",
            "\n",
            "Получено предложений: 5784\n",
            "\n",
            "Всего токенов: 98,887\n",
            "Уникальных слов: 24,479\n",
            "\n",
            "Биграмм: 76,268\n",
            "Триграмм: 83,769\n",
            "\n",
            "Топ-8 биграмм:\n",
            "  и            → в            : 183\n",
            "  и            → с            : 111\n",
            "  я            → не           : 72\n",
            "  и            → не           : 54\n",
            "  и            → на           : 52\n",
            "  я            → в            : 49\n",
            "  и            → ты           : 47\n",
            "  мой          → друг         : 44\n",
            "\n",
            "Топ-6 триграмм:\n",
            "  в        последний → раз      : 16\n",
            "  ты       помнишь  → ли       : 12\n",
            "  с        сватьей  → бабой    : 11\n",
            "  сватьей  бабой    → бабарихой : 11\n",
            "  а        ткачиха  → с        : 10\n",
            "  ткачиха  с        → поварихой : 10\n",
            "\n",
            "======================================================================\n",
            "ГЕНЕРАЦИЯ СТИХОВ\n",
            "\n",
            "Вариант 1: биграммы, начало «луна», температура 1.1\n",
            "  луна в истине блаженство я со груди свобода\n",
            "  вдруг сердито тотчас ведьму ль нам от плодов\n",
            "  хотел и медлят поминутно спицы к восторженной душой\n",
            "  уснуть уж их ужасным голосам и нарекся князь\n",
            "\n",
            "Вариант 2: триграммы, начало «мой», температура 0.75\n",
            "  мой друг таков был сумрачный ужасный до конца\n",
            "  с душой задумчивой я ныне стал поэт и\n",
            "  терном славы не свершил возвышенных творений я скоро\n",
            "  весь умру и и о гроб невесты милой\n",
            "\n",
            "Вариант 3: триграммы, случайный старт, высокая температура\n",
            "  лавровой но в кельях тихо и темно что\n",
            "  очень стыдно и грешно и и о шпору\n",
            "  вдруг ударилась громобуря крепко спавшего загремела раздвоилася отлетела\n",
            "  в разны стороны храбрый воин пробуждается озирает шпору\n",
            "\n",
            "Модели сохранены в bi_model.json и tri_model.json\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Генерация стихов в стиле А.С. Пушкина\n",
        "n-граммная языковая модель (биграммы и триграммы)\n",
        "Семинар 2, ИДС / NLP\n",
        "\"\"\"\n",
        "\n",
        "import re\n",
        "import random\n",
        "import json\n",
        "from collections import defaultdict, Counter\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# =============================================================================\n",
        "# 1. Загрузка и предобработка текста\n",
        "# =============================================================================\n",
        "\n",
        "PATH = \"pushkin.txt\"  # предполагаем, что файл уже скачан и лежит рядом\n",
        "\n",
        "with open(PATH, encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "# Очень простая очистка\n",
        "raw_text = raw_text.replace(\"\\xa0\", \" \").replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
        "raw_text = re.sub(r'\\s+', ' ', raw_text).strip()\n",
        "\n",
        "print(f\"Длина текста после очистки: {len(raw_text):,} символов\")\n",
        "print(\"Начало текста:\", raw_text[:180], \"...\\n\")\n",
        "\n",
        "# Разбиваем на предложения (очень грубо)\n",
        "sentences = [s.strip() for s in re.split(r'[.!?]\\s*', raw_text) if len(s.strip()) > 30]\n",
        "print(f\"Получено предложений: {len(sentences)}\\n\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 2. Токенизация (только русские слова, нижний регистр)\n",
        "# =============================================================================\n",
        "\n",
        "def simple_tokenize(s: str) -> list[str]:\n",
        "    \"\"\"Оставляем только кириллические слова\"\"\"\n",
        "    return re.findall(r'[а-яё]+', s.lower())\n",
        "\n",
        "\n",
        "tokenized = [simple_tokenize(sent) for sent in sentences]\n",
        "all_tokens = [tok for sent in tokenized for tok in sent]\n",
        "\n",
        "print(f\"Всего токенов: {len(all_tokens):,}\")\n",
        "print(f\"Уникальных слов: {len(set(all_tokens)):,}\\n\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 3. Подсчёт n-грамм\n",
        "# =============================================================================\n",
        "\n",
        "# Униграммы\n",
        "uni_count = Counter(all_tokens)\n",
        "\n",
        "# Биграммы\n",
        "bi_count = defaultdict(int)\n",
        "bi_prefix_count = defaultdict(int)          # сколько раз встретился первый элемент\n",
        "\n",
        "for sent in tokenized:\n",
        "    for i in range(len(sent) - 1):\n",
        "        pair = (sent[i], sent[i+1])\n",
        "        bi_count[pair] += 1\n",
        "        bi_prefix_count[sent[i]] += 1\n",
        "\n",
        "# Триграммы\n",
        "tri_count = defaultdict(int)\n",
        "tri_prefix_count = defaultdict(int)         # сколько раз встретилась биграмма-префикс\n",
        "\n",
        "for sent in tokenized:\n",
        "    for i in range(len(sent) - 2):\n",
        "        triple = (sent[i], sent[i+1], sent[i+2])\n",
        "        tri_count[triple] += 1\n",
        "        bi_prefix = (sent[i], sent[i+1])\n",
        "        tri_prefix_count[bi_prefix] += 1\n",
        "\n",
        "\n",
        "print(f\"Биграмм: {len(bi_count):,}\")\n",
        "print(f\"Триграмм: {len(tri_count):,}\\n\")\n",
        "\n",
        "print(\"Топ-8 биграмм:\")\n",
        "for pair, cnt in sorted(bi_count.items(), key=lambda x: -x[1])[:8]:\n",
        "    print(f\"  {pair[0]:<12} → {pair[1]:<12} : {cnt}\")\n",
        "\n",
        "print(\"\\nТоп-6 триграмм:\")\n",
        "for trip, cnt in sorted(tri_count.items(), key=lambda x: -x[1])[:6]:\n",
        "    print(f\"  {trip[0]:<8} {trip[1]:<8} → {trip[2]:<8} : {cnt}\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 4. Функции семплирования\n",
        "# =============================================================================\n",
        "\n",
        "def get_candidates_bi(word: str) -> tuple[list[str], list[float]]:\n",
        "    \"\"\"Вероятности следующего слова после данного (биграммная модель)\"\"\"\n",
        "    if word not in bi_prefix_count:\n",
        "        return [], []\n",
        "    total = bi_prefix_count[word]\n",
        "    next_words = []\n",
        "    probs = []\n",
        "    for (w1, w2), c in bi_count.items():\n",
        "        if w1 == word:\n",
        "            next_words.append(w2)\n",
        "            probs.append(c / total)\n",
        "    return next_words, probs\n",
        "\n",
        "\n",
        "def get_candidates_tri(w1: str, w2: str) -> tuple[list[str], list[float]]:\n",
        "    \"\"\"Вероятности после двух слов (триграммная модель)\"\"\"\n",
        "    prefix = (w1, w2)\n",
        "    if prefix not in tri_prefix_count:\n",
        "        return [], []\n",
        "    total = tri_prefix_count[prefix]\n",
        "    next_words = []\n",
        "    probs = []\n",
        "    for (a, b, c), cnt in tri_count.items():\n",
        "        if (a, b) == prefix:\n",
        "            next_words.append(c)\n",
        "            probs.append(cnt / total)\n",
        "    return next_words, probs\n",
        "\n",
        "\n",
        "def apply_temperature(probs: list[float], temp: float = 1.0) -> list[float]:\n",
        "    if not probs:\n",
        "        return []\n",
        "    if temp <= 0:\n",
        "        temp = 1e-6\n",
        "    logits = np.log(np.array(probs) + 1e-12)\n",
        "    logits = logits / temp\n",
        "    exp_logits = np.exp(logits)\n",
        "    return (exp_logits / exp_logits.sum()).tolist()\n",
        "\n",
        "\n",
        "def sample_word(cands: list[str], probs: list[float], temp: float = 1.0) -> str:\n",
        "    if not cands:\n",
        "        # запасной вариант — самое частое слово\n",
        "        return uni_count.most_common(1)[0][0]\n",
        "    \n",
        "    probs = apply_temperature(probs, temp)\n",
        "    return random.choices(cands, weights=probs, k=1)[0]\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 5. Генерация четверостишия\n",
        "# =============================================================================\n",
        "\n",
        "def generate_poem(\n",
        "    model: str = \"tri\",           # \"bi\" или \"tri\"\n",
        "    start_word: str = None,\n",
        "    temp: float = 0.9,\n",
        "    words_per_line: int = 8,\n",
        "    lines: int = 4\n",
        ") -> list[str]:\n",
        "    \n",
        "    if start_word is None:\n",
        "        start_word = random.choice(list(uni_count.keys()))\n",
        "    \n",
        "    poem_tokens = [start_word]\n",
        "    \n",
        "    while len(poem_tokens) < words_per_line * lines:\n",
        "        if model == \"tri\" and len(poem_tokens) >= 2:\n",
        "            cands, pr = get_candidates_tri(poem_tokens[-2], poem_tokens[-1])\n",
        "        else:\n",
        "            cands, pr = get_candidates_bi(poem_tokens[-1])\n",
        "        \n",
        "        next_w = sample_word(cands, pr, temp)\n",
        "        poem_tokens.append(next_w)\n",
        "    \n",
        "    # Разбиваем на строки\n",
        "    poem_lines = []\n",
        "    for i in range(0, len(poem_tokens), words_per_line):\n",
        "        line_tokens = poem_tokens[i : i + words_per_line]\n",
        "        poem_lines.append(\" \".join(line_tokens))\n",
        "    \n",
        "    poem_lines = poem_lines[:lines]\n",
        "    \n",
        "    # Очень наивная попытка рифмы (повторяем последнее слово 2-й строки в 4-й)\n",
        "    if len(poem_lines) >= 4 and random.random() < 0.65:\n",
        "        try:\n",
        "            rhyme_word = poem_lines[1].split()[-1]\n",
        "            last_line_words = poem_lines[3].split()[:-1]\n",
        "            poem_lines[3] = \" \".join(last_line_words + [rhyme_word])\n",
        "        except:\n",
        "            pass  # если строка слишком короткая — пропускаем\n",
        "    \n",
        "    return poem_lines\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 6. Запуск и демонстрация\n",
        "# =============================================================================\n",
        "\n",
        "random.seed(43)   # чуть другой сид\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ГЕНЕРАЦИЯ СТИХОВ\\n\")\n",
        "\n",
        "print(\"Вариант 1: биграммы, начало «луна», температура 1.1\")\n",
        "poem_bi = generate_poem(model=\"bi\", start_word=\"луна\", temp=1.1)\n",
        "for ln in poem_bi:\n",
        "    print(\"  \" + ln)\n",
        "\n",
        "print(\"\\nВариант 2: триграммы, начало «мой», температура 0.75\")\n",
        "poem_tri = generate_poem(model=\"tri\", start_word=\"мой\", temp=0.75)\n",
        "for ln in poem_tri:\n",
        "    print(\"  \" + ln)\n",
        "\n",
        "print(\"\\nВариант 3: триграммы, случайный старт, высокая температура\")\n",
        "poem_random = generate_poem(model=\"tri\", temp=1.6)\n",
        "for ln in poem_random:\n",
        "    print(\"  \" + ln)\n",
        "\n",
        "\n",
        "# Сохранение моделей (для отчёта или повторного использования)\n",
        "with open(\"bi_model.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump({f\"{a}_{b}\": cnt for (a,b), cnt in bi_count.items()}, f, ensure_ascii=False, indent=1)\n",
        "\n",
        "with open(\"tri_model.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump({f\"{a}_{b}_{c}\": cnt for (a,b,c), cnt in tri_count.items()}, f, ensure_ascii=False, indent=1)\n",
        "\n",
        "print(\"\\nМодели сохранены в bi_model.json и tri_model.json\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
